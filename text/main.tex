\documentclass[a4paper]{article}

%% Language and font encodings
\usepackage[english]{babel}
\usepackage[utf8x]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{amssymb, amsbsy, amsmath}
\usepackage{array, booktabs, longtable}
\usepackage{graphicx}
\usepackage[x11names, table]{xcolor}
\usepackage{caption}
\DeclareCaptionFont{blue}{\color{LightSteelBlue3}}

\newcommand{\foo}{\color{LightSteelBlue3}\makebox[0pt]{\tiny\textbullet}\hskip-0.5pt\vrule width 1pt\hspace{\labelsep}}
\newcommand{\bfoo}{\raisebox{2.1ex}[0pt]{\makebox[\dimexpr2\tabcolsep]%
{\color{LightSteelBlue3}\tiny\textbullet}}}%
\newcommand{\tfoo}{\makebox[\dimexpr2\tabcolsep]%
{\color{LightSteelBlue3}$\boldsymbol \uparrow $}}%
%% Sets page size and margins
\usepackage[a4paper,top=3cm,bottom=2cm,left=3cm,right=3cm,marginparwidth=1.75cm]{geometry}
\usepackage{url}

\title{Practical course robotics \\ project proposal}
\author{Marc Tuscher, Ralf Gulde}
\date{\today}
\begin{document}
\maketitle

\section{Introduction}
Recent advancements in robotics and automated systems have led to the expansion of autonomous capabilities and more intelligent machines being utilised in ever more varied applications \cite{1Visual_learning_2005, 2Teleoperation:2014}.
While manipulating objects is relatively easy for humans, reliable grasping arbitrary objects remains an open challange for general-purpose robots.
Resolving it would advance the application of robotics to industrial use cases, such as part assembly, binning, and sorting.
The capability of adapting to changing environments is a necessary skill for task generalised robots \cite{3Robot_learning_2012, 4Imitation_and_Reinforcement_Learning_2010}.
A grasp describes how a robotic end-effector can be arranged to securely grab an object and successfully lift.
Grasp planning relates to the path planning process that is required to securely grasp the object and maintain the closed gripper contacts to hold and lift the object from its resting surface \cite{5Robotic_grasping_and_contact}.
Initially, deriving the grasp-points of a perceived object is an essential aspects.
Consequently, accurate and diverse detection of robotic grasp candidates for target objects should lead to a better grasp path planning and improve the overall performance of grasp-based manipulation tasks.

In this work we propose a deep learning strategy to detect grasp points from raw sensor data and plan collision free robot paths to manipulate arbitrary objects.
In the past decade, deep learning has achieved major success on detection, classification, and regression tasks \cite{6bo2013unsupervised, 7krizhevsky2012imagenet}. 
Its key strength is the ability to leverage large quantities of labelled and unlabelled data to learn powerful representations without hand-engineering the feature space.
To conclude this work we experimentally validate our approach using a humanoid robotic system and a structured light RGB-D sensor.

This project proposal is organized as follows: In section \ref{2sec_goal} the goal of the work is described. 
Further, in section \ref{3sec_prob_n_meth} a formulation and the proposed methods are described.
Section \ref{4_sec_milestones} thematizes the milestones of implementing the approach in a robotic demonstator system to evaluate the proposed approach.


\section{Goal (Ralf)} 
\label{2sec_goal}

Goals:

* detect parallel jaw grasps a priori unknown objects

* plan collision free paths 

* drop the grasped object in a bin


Restrictions:

* dynamic changing environments are not considered

* objecte must in principle be manipulable by a two-finger parallel gripper.


optional

* suction cup gripper


Robot grasping can be subdivided into two related problems: perception and planning.
A typical example of this approach is the ROS grasp pipeline~~\cite{chitta_perception_2012}.
Herein, a CAD model is mapped to a point cloud of the object.
Optimal grasp poses are then derived from the CAD model. 
This works well in ideal scenarios, however, in most realistic applications the scenario is far from ideal.
Our main goal is to set up a framework which extracts robust grasp poses from RGBD-Images and grasps an object lying on a table.

\section{Problems and methods}
\label{3sec_prob_n_meth}
This section gives an overview over the general problems of the objective and the methods we will use to overcome these difficulties.


\begin{itemize}
    \item Problems:\\
    \begin{itemize}
        \item Localization of objects.
        \item Localization of robust grasp points.
    \end{itemize}
    \item Methods:\\
    \begin{itemize}
        \item Robot control using \textit{rai} framework
        \item Sampling of grasp candidates using a grasping policy (e.g. \textit{CrossEntropyRobustGraspingPolicy}\footnote{\url{https://github.com/BerkeleyAutomation/gqcnn/blob/a0930e9d2fef3c930c41dd91cde902d261348fbe/gqcnn/grasping/policy/policy.py#L627}}) 
        \item evaluation of grasp candidates with pretrained \textit{GQCNN}\footnote{\url{https://github.com/BerkeleyAutomation/gqcnn}}
        \item localization of objects using bounding boxes (if necessary)
    \end{itemize}
\end{itemize}

\subsection{Perception (Ralf)}
\label{3_1subsec_perception}
needs to be infered if more than one object is in the scene. We will use a 
SSD for that.
\subsection{Motion Planning (Marc)}
\label{3_2subsec_motion_planning}
Sampling grasp points from RGBD-Images is a major problem and has been studied by a wide variety of approaches.
A core problem in robot motion planning and robotics in general is defined as: given a cartesian position $y \in \mathbb{R}^d$, find a corresponding joint configuration $q \in \mathbb{R}^n$ such that
\begin{equation}
    y = \phi(q),  \phi : \mathbb{R}^n \rightarrow \mathbb{R}^d
\end{equation}
In robotics this problem is referred to as the inverse kinematics problem.
We formulate this problem as a constrained optimization problem 
\begin{equation}
    \min_x f(x) \ \text{s.t.} \ g(x) \leq 0, \  h(x) = 0
\end{equation}
where different objectives can be defined. 
Such objectives can either be equality constraints $h$, e.g. the distance between to frames, inequality constraints $g$ or costs terms $f$.
The generality of this formulation allows to directly incorporate constraints for avoiding collisions.
To solve this constrained optimization problem we rely on the KOMO library which formulates the constrained optimization problem as an unconstrained optimization problem, which is then solved using Newtons method~\cite{laumond_tutorial_2017}.
As a first step, we only use inverse kinematics with some kind of collision avoidance for motion planning. 
For further improvements we test the path planning feature of the KOMO library which allows to calculate complete trajectories for path planning.



\section{Milestones}
\label{4_sec_milestones}F
TODO

blabla


\begin{figure}[b]
    \label{timeline}
\renewcommand\arraystretch{1.4}\arrayrulecolor{LightSteelBlue3}
\begin{longtable}{@{\,}r <{\hskip 2pt} !{\foo} >{\raggedright\arraybackslash}p{5cm} p{5cm}}
%\caption{Timeline} \\[-1.5ex]
%\toprule
\addlinespace[1.5ex] 
 &  \textbf{Marc} & \textbf{Ralf}  \\
16.05.19 & Basic setup, process RGBD images from Baxter/PR2 with GQCNN & Ralfas asdasdasda sdas dasd asdasd as dasd\\
23.05.19 & Grasp object with default grasping policy & \\
06.06.19 & Tune control, recalculate online if object moves &\\
13.06.19 & Experiment with different grasping policies &\\
\end{longtable}
\end{figure}

\subsection*{Requirements}
\begin{itemize}
    \item Baxter
    \item PR2
    \item Optional: machine with GPU for further training. We can also bring our own desktop pc.
    \item Details about camera intrinsics
    \item RAI framework running on machines with nvidia graphics card (but this problem might be related to the newest nvidia-driver.)
\end{itemize}


\bibliographystyle{alpha}
\bibliography{main}
\end{document}


