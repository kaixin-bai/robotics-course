\documentclass[a4paper]{article}

%% Language and font encodings
\usepackage[english]{babel}
\usepackage[utf8x]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{amssymb, amsbsy, amsmath}
\usepackage{array, booktabs, longtable}
\usepackage{graphicx}
\usepackage[x11names, table]{xcolor}
\usepackage{caption}
\DeclareCaptionFont{blue}{\color{LightSteelBlue3}}

\newcommand{\foo}{\color{LightSteelBlue3}\makebox[0pt]{\tiny\textbullet}\hskip-0.5pt\vrule width 1pt\hspace{\labelsep}}
\newcommand{\bfoo}{\raisebox{2.1ex}[0pt]{\makebox[\dimexpr2\tabcolsep]%
{\color{LightSteelBlue3}\tiny\textbullet}}}%
\newcommand{\tfoo}{\makebox[\dimexpr2\tabcolsep]%
{\color{LightSteelBlue3}$\boldsymbol \uparrow $}}%
%% Sets page size and margins
\usepackage[a4paper,top=3cm,bottom=2cm,left=3cm,right=3cm,marginparwidth=1.75cm]{geometry}
\usepackage{url}

\title{Practical course robotics \\ project proposal}
\author{Marc Tuscher, Ralf Gulde}
\date{\today}
\begin{document}
\maketitle

\section{Introduction}
Recent advancements in robotics and automated systems have led to the expansion of autonomous capabilities and more intelligent machines being utilised in ever more varied applications \cite{1Visual_learning_2005, 2Teleoperation:2014}.
While manipulating objects is relatively easy for humans, reliable grasping arbitrary objects remains an open challange for general-purpose robots.
Resolving it would advance the application of robotics to industrial use cases, such as part assembly, binning, and sorting.
The capability of adapting to changing environments is a necessary skill for task generalised robots \cite{3Robot_learning_2012, 4Imitation_and_Reinforcement_Learning_2010}.
A grasp describes how a robotic end-effector can be arranged to securely grab an object and successfully lift.
Grasp planning relates to the path planning process that is required to securely grasp the object and maintain the closed gripper contacts to hold and lift the object from its resting surface \cite{5Robotic_grasping_and_contact}.
Initially, deriving the grasp-points of a perceived object is an essential aspects.
Consequently, accurate and diverse detection of robotic grasp candidates for target objects should lead to a better grasp path planning and improve the overall performance of grasp-based manipulation tasks.

In this work we propose a deep learning strategy to detect grasp points from raw sensor data and plan collision free robot paths to manipulate arbitrary objects.
In the past decade, deep learning has achieved major success on detection, classification, and regression tasks \cite{6bo2013unsupervised, 7krizhevsky2012imagenet}. 
Its key strength is the ability to leverage large quantities of labelled and unlabelled data to learn powerful representations without hand-engineering the feature space.
To conclude this work we experimentally validate our approach using a humanoid robotic system and a structured light RGB-D sensor.

This project proposal is organized as follows: In section \ref{2sec_goal} the goal of the work is described. 
Further, in section \ref{3sec_prob_n_meth} a formulation and the proposed methods are described.
Section \ref{4_sec_milestones} thematizes the milestones of implementing the approach in a robotic demonstator system to evaluate the proposed approach.


\section{Goal} 
\label{2sec_goal}

The main goal in this project is to set up a framework which is able to detect a stable grasp pose of unkown objects and grab these objects using a parallel jaw gripper.
This includes recognizing objects and their positions in the camera frame as well as identifying stable grasp poses.
In order to execute a grasp, such a pose is transformed into cartesian coordinates in the world frame.
Further, it also includes collision free planning of robot motion in order to execute the manipulation.
We will not consider dynamic changing environments or objects which are not manipulable using a parallel jaw gripper. 
However, we plan to experiment with an extension to this approach using a suction cup gripper.

\section{Problems and methods}
\label{3sec_prob_n_meth}
This section gives an overview over the general problems of the objective and the methods we will use to overcome these difficulties.


\begin{itemize}
    \item Problems:\\
    \begin{itemize}
        \item Localization of objects.
        \item Localization of robust grasp points.
    \end{itemize}
    \item Methods:\\
    \begin{itemize}
        \item Robot control using \textit{rai} framework
        \item Sampling of grasp candidates using a grasping policy (e.g. \textit{CrossEntropyRobustGraspingPolicy}\footnote{\url{https://github.com/BerkeleyAutomation/gqcnn/blob/a0930e9d2fef3c930c41dd91cde902d261348fbe/gqcnn/grasping/policy/policy.py#L627}}) 
        \item evaluation of grasp candidates with pretrained \textit{GQCNN}\footnote{\url{https://github.com/BerkeleyAutomation/gqcnn}}
        \item localization of objects using bounding boxes (if necessary)
    \end{itemize}
\end{itemize}

\subsection{Perception}
\label{3_1subsec_perception}
needs to be infered if more than one object is in the scene. We will use a 
SSD for that.
\subsection{Motion Planning}
\label{3_2subsec_motion_planning}
Sampling grasp points from RGBD-Images is a major problem and has been studied by a wide variety of approaches.
A core problem in robot motion planning and robotics in general is defined as: given a cartesian position $y \in \mathbb{R}^d$, find a corresponding joint configuration $q \in \mathbb{R}^n$ such that
\begin{equation}
    y = \phi(q),  \phi : \mathbb{R}^n \rightarrow \mathbb{R}^d
\end{equation}
In robotics this problem is referred to as the inverse kinematics problem.
We formulate this problem as a constrained optimization problem 
\begin{equation}
    \min_x f(x) \ \text{s.t.} \ g(x) \leq 0, \  h(x) = 0
\end{equation}
where different objectives can be defined. 
Such objectives can either be equality constraints $h$, e.g. the distance between to frames, inequality constraints $g$ or costs terms $f$.
The generality of this formulation allows to directly incorporate constraints for avoiding collisions.
To solve this constrained optimization problem we rely on the KOMO library which formulates the constrained optimization problem as an unconstrained optimization problem, which is then solved using Newtons method~\cite{laumond_tutorial_2017}.
As a first step, we only use inverse kinematics with some kind of collision avoidance for motion planning. 
For further improvements we test the path planning feature of the KOMO library which allows to calculate complete trajectories for path planning.


\clearpage
\section{Milestones}
\label{4_sec_milestones}

The following section presents a timeline which serves as a workplan for the project.

\renewcommand\arraystretch{1.4}\arrayrulecolor{LightSteelBlue3}
\begin{longtable}{@{\,}r <{\hskip 2pt} !{\foo} >{\raggedright\arraybackslash}p{5cm} p{5cm}}
%\caption{Timeline} \\[-1.5ex]
%\toprule
\addlinespace[1.5ex] 
 & \multicolumn{1}{c}{\textbf{Marc}}  & \multicolumn{1}{c}{\textbf{Ralf}}  \\[10pt]
16.05.19 & get \textit{RAI} running on machines with nvidia gpu & port \textit{GQCNN} to python3, load pretrained model and basic setup\\[5pt]
23.05.19 & set up bounding box detector for object localization & transform the output pose of \textit{GQCNN} into cartesian coordinates\\[5pt]
06.06.19 & Tune control, test KOMO path planning & optimize prediction speed, check online capabilities\\[5pt]
13.06.19 & Tune camera intrinsics with tensorflow-graphics\footnote{\url{https://github.com/tensorflow/graphics}} & Experiment on combining opencv pipeline and \textit{GQCNN} \\[5pt]
20.06.19 & \multicolumn{2}{c}{experimental validation of the approach in several grasp scenarios} \\
rest of time & \multicolumn{2}{c}{ \textbf{cleanup super messy code}}
\end{longtable}


\clearpage
\bibliographystyle{alpha}
\bibliography{main}
\end{document}


